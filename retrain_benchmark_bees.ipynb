{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name accumulate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8828ef685389>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccumulate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name accumulate"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import operator\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "#from itertools import accumulate\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
    "    'densenet121': 'https://download.pytorch.org/models/densenet121-241335ed.pth',\n",
    "    'densenet169': 'https://download.pytorch.org/models/densenet169-6f0f7f60.pth',\n",
    "    'densenet201': 'https://download.pytorch.org/models/densenet201-4c113574.pth',\n",
    "    'densenet161': 'https://download.pytorch.org/models/densenet161-17b70270.pth',\n",
    "    #truncated _google to match module name\n",
    "    'inception_v3': 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth',\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',    \n",
    "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
    "    'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
    "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',    \n",
    "}\n",
    "\n",
    "model_names = model_urls.keys()\n",
    "\n",
    "input_sizes = {\n",
    "    'alexnet' : (224,224),\n",
    "    'densenet': (224,224),\n",
    "    'resnet' : (224,224),\n",
    "    'inception' : (299,299),\n",
    "    'squeezenet' : (224,224),#not 255,255 acc. to https://github.com/pytorch/pytorch/issues/1120\n",
    "    'vgg' : (224,224)\n",
    "}\n",
    "\n",
    "models_to_test = ['alexnet', 'densenet169', 'inception_v3', \\\n",
    "                  'resnet34', 'squeezenet1_1', 'vgg13']\n",
    "\n",
    "batch_size = 4\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic pretrained model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We solve the dimensionality mismatch between\n",
    "#final layers in the constructed vs pretrained\n",
    "#modules at the data level.\n",
    "def diff_states(dict_canonical, dict_subset):\n",
    "    names1, names2 = (list(dict_canonical.keys()), list(dict_subset.keys()))\n",
    "    \n",
    "    #Sanity check that param names overlap\n",
    "    #Note that params are not necessarily in the same order\n",
    "    #for every pretrained model\n",
    "    not_in_1 = [n for n in names1 if n not in names2]\n",
    "    not_in_2 = [n for n in names2 if n not in names1]\n",
    "    assert len(not_in_1) == 0\n",
    "    assert len(not_in_2) == 0\n",
    "\n",
    "    for name, v1 in dict_canonical.items():\n",
    "        v2 = dict_subset[name]\n",
    "        assert hasattr(v2, 'size')\n",
    "        if v1.size() != v2.size():\n",
    "            yield (name, v1)                \n",
    "\n",
    "def load_model_merged(name, num_classes):\n",
    "    \n",
    "    model = models.__dict__[name](num_classes=num_classes)\n",
    "    \n",
    "    #Densenets don't (yet) pass on num_classes, hack it in for 169\n",
    "    if name == 'densenet169':\n",
    "        model = torchvision.models.DenseNet(num_init_features=64, growth_rate=32, \\\n",
    "                                            block_config=(6, 12, 32, 32), num_classes=num_classes)\n",
    "        \n",
    "    pretrained_state = model_zoo.load_url(model_urls[name])\n",
    "\n",
    "    #Diff\n",
    "    diff = [s for s in diff_states(model.state_dict(), pretrained_state)]\n",
    "    print(\"Replacing the following state from initialized\", name, \":\", \\\n",
    "          [d[0] for d in diff])\n",
    "    \n",
    "    for name, value in diff:\n",
    "        pretrained_state[name] = value\n",
    "    \n",
    "    assert len([s for s in diff_states(model.state_dict(), pretrained_state)]) == 0\n",
    "    \n",
    "    #Merge\n",
    "    model.load_state_dict(pretrained_state)\n",
    "    return model, diff\n",
    "\n",
    "\n",
    "def filtered_params(net, param_list=None):\n",
    "    def in_param_list(s):\n",
    "        for p in param_list:\n",
    "            if s.endswith(p):\n",
    "                return True\n",
    "        return False    \n",
    "    #Caution: DataParallel prefixes '.module' to every parameter name\n",
    "    params = net.named_parameters() if param_list is None \\\n",
    "    else (p for p in net.named_parameters() if in_param_list(p[0]))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Todo: split function into separate test and train data\n",
    "#To get the tutorial data (bee vs. ants), go to:\n",
    "#http://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "def get_data(resize):\n",
    "\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomSizedCrop(max(resize)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            #Higher scale-up for inception\n",
    "            transforms.Scale(int(max(resize)/224*256)),\n",
    "            transforms.CenterCrop(max(resize)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    data_dir = 'hymenoptera_data'\n",
    "    dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "             for x in ['train', 'val']}\n",
    "    dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=batch_size,\n",
    "                                                   shuffle=True)\n",
    "                    for x in ['train', 'val']}\n",
    "    dset_sizes = {x: len(dsets[x]) for x in ['train', 'val']}\n",
    "    dset_classes = dsets['train'].classes\n",
    "    \n",
    "    return dset_loaders['train'], dset_loaders['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, param_list=None, epochs=15):\n",
    "    def in_param_list(s):\n",
    "        for p in param_list:\n",
    "            if s.endswith(p):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if use_gpu:\n",
    "        criterion = criterion.cuda()\n",
    "    \n",
    "    params = (p for p in filtered_params(net, param_list))\n",
    "    \n",
    "    #If finetuning model, turn off grad for other params\n",
    "    if param_list:\n",
    "        for p_fixed in (p for p in net.named_parameters() if not in_param_list(p[0])):\n",
    "            p_fixed[1].requires_grad = False            \n",
    "    \n",
    "    #Optimizer as in tutorial\n",
    "    optimizer = optim.SGD((p[1] for p in params), lr=0.001, momentum=0.9)\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda(async=True))\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            loss = None\n",
    "            # for nets that have multiple outputs such as inception\n",
    "            if isinstance(outputs, tuple):\n",
    "                loss = sum((criterion(o,labels) for o in outputs))\n",
    "            else:\n",
    "                loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.data[0]\n",
    "            if i % 30 == 29:\n",
    "                avg_loss = running_loss / 30\n",
    "                losses.append(avg_loss)\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, avg_loss))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    return losses\n",
    "\n",
    "### helper function to replace itertools.accumulate\n",
    "def accumulate(iterable, func=operator.add):\n",
    "    'Return running totals'\n",
    "    # accumulate([1,2,3,4,5]) --> 1 3 6 10 15\n",
    "    # accumulate([1,2,3,4,5], operator.mul) --> 1 2 6 24 120\n",
    "    it = iter(iterable)\n",
    "    try:\n",
    "        total = next(it)\n",
    "    except StopIteration:\n",
    "        return\n",
    "    yield total\n",
    "    for element in it:\n",
    "        total = func(total, element)\n",
    "        yield total\n",
    "        \n",
    "#simpler implementation\n",
    "#def accumulate(iterator):\n",
    "#    total = 0\n",
    "#    for item in iterator:\n",
    "#        total += item\n",
    "#        yield total\n",
    "\n",
    "#Get stats for training and evaluation in a structured way\n",
    "#If param_list is None all relevant parameters are tuned,\n",
    "#otherwise, only parameters that have been constructed for custom\n",
    "#num_classes\n",
    "def train_stats(m, trainloader, param_list = None):\n",
    "    stats = {}\n",
    "    params = filtered_params(m, param_list)    \n",
    "    counts = 0,0\n",
    "    for counts in enumerate(accumulate((reduce(lambda d1,d2: d1*d2, p[1].size()) for p in params)) ):\n",
    "        pass\n",
    "    stats['variables_optimized'] = counts[0] + 1\n",
    "    stats['params_optimized'] = counts[1]\n",
    "    \n",
    "    before = time.time()\n",
    "    losses = train(m, trainloader, param_list=param_list)\n",
    "    stats['training_time'] = time.time() - before\n",
    "\n",
    "    stats['training_loss'] = losses[-1] if len(losses) else float('nan')\n",
    "    stats['training_losses'] = losses\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def evaluate_stats(net, testloader):\n",
    "    stats = {}\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    before = time.time()\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        images, labels = data\n",
    "\n",
    "        if use_gpu:\n",
    "            images, labels = (images.cuda()), (labels.cuda(async=True))\n",
    "\n",
    "        outputs = net(Variable(images))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    print(\"correct/total: %d/%d\" % (correct, total))    \n",
    "    accuracy = correct*1.0 / total\n",
    "    stats['accuracy'] = accuracy\n",
    "    stats['eval_time'] = time.time() - before\n",
    "    \n",
    "    print('Accuracy on test images: %f' % accuracy)\n",
    "    return stats\n",
    "\n",
    "\n",
    "# In[209]:\n",
    "\n",
    "def train_eval(net, trainloader, testloader, param_list=None):\n",
    "    print(\"Training...\" if not param_list else \"Retraining...\")\n",
    "    stats_train = train_stats(net, trainloader, param_list=param_list)\n",
    "    \n",
    "    print(\"Evaluating...\")\n",
    "    net = net.eval()\n",
    "    stats_eval = evaluate_stats(net, testloader)\n",
    "    \n",
    "    #return {**stats_train, **stats_eval}\n",
    "\n",
    "#    stats_copy = deepcopy(stats_train)\n",
    "#    stats_copy.update(stats_eval)\n",
    "#    return stats_copy\n",
    "\n",
    "    stats_out = {}\n",
    "    stats_out.update(stats_train)\n",
    "    stats_out.update(stats_eval)\n",
    "    return stats_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RETRAINING\n",
      "\n",
      "Targeting alexnet with 2 classes\n",
      "------------------------------------------\n",
      "('Replacing the following state from initialized', 'alexnet', ':', ['classifier.6.weight', 'classifier.6.bias'])\n",
      "('Resizing input images to max of', (224, 224))\n",
      "Transfering models to GPU(s)\n",
      "Retraining...\n",
      "[1,    30] loss: 0.845\n",
      "[1,    60] loss: 0.912\n",
      "[2,    30] loss: 0.763\n",
      "[2,    60] loss: 1.098\n",
      "[3,    30] loss: 0.788\n",
      "[3,    60] loss: 0.805\n",
      "[4,    30] loss: 0.119\n",
      "[4,    60] loss: 0.716\n",
      "[5,    30] loss: 0.809\n",
      "[5,    60] loss: 0.827\n",
      "[6,    30] loss: 0.691\n",
      "[6,    60] loss: 0.496\n",
      "[7,    30] loss: 0.607\n",
      "[7,    60] loss: 0.372\n",
      "[8,    30] loss: 0.225\n",
      "[8,    60] loss: 0.361\n",
      "[9,    30] loss: 0.285\n",
      "[9,    60] loss: 0.395\n",
      "[10,    30] loss: 0.640\n",
      "[10,    60] loss: 0.387\n",
      "[11,    30] loss: 0.072\n",
      "[11,    60] loss: 0.297\n",
      "[12,    30] loss: 0.181\n",
      "[12,    60] loss: 0.217\n",
      "[13,    30] loss: 0.333\n",
      "[13,    60] loss: 0.305\n",
      "[14,    30] loss: 0.103\n",
      "[14,    60] loss: 0.238\n",
      "[15,    30] loss: 0.473\n",
      "[15,    60] loss: 0.036\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 137/153\n",
      "Accuracy on test images: 0.895425\n",
      "\n",
      "\n",
      "Targeting densenet169 with 2 classes\n",
      "------------------------------------------\n",
      "('Replacing the following state from initialized', 'densenet169', ':', ['classifier.weight', 'classifier.bias'])\n",
      "('Resizing input images to max of', (224, 224))\n",
      "Transfering models to GPU(s)\n",
      "Retraining...\n",
      "[1,    30] loss: 0.742\n",
      "[1,    60] loss: 0.494\n",
      "[2,    30] loss: 0.483\n",
      "[2,    60] loss: 0.426\n",
      "[3,    30] loss: 0.619\n",
      "[3,    60] loss: 0.456\n",
      "[4,    30] loss: 0.393\n",
      "[4,    60] loss: 0.702\n",
      "[5,    30] loss: 0.612\n",
      "[5,    60] loss: 0.375\n",
      "[6,    30] loss: 0.398\n",
      "[6,    60] loss: 0.365\n",
      "[7,    30] loss: 0.229\n",
      "[7,    60] loss: 0.595\n",
      "[8,    30] loss: 0.384\n",
      "[8,    60] loss: 0.547\n",
      "[9,    30] loss: 0.366\n",
      "[9,    60] loss: 0.325\n",
      "[10,    30] loss: 0.280\n",
      "[10,    60] loss: 0.345\n",
      "[11,    30] loss: 0.466\n",
      "[11,    60] loss: 0.509\n",
      "[12,    30] loss: 0.285\n",
      "[12,    60] loss: 0.347\n",
      "[13,    30] loss: 0.472\n",
      "[13,    60] loss: 0.354\n",
      "[14,    30] loss: 0.284\n",
      "[14,    60] loss: 0.420\n",
      "[15,    30] loss: 0.367\n",
      "[15,    60] loss: 0.509\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 145/153\n",
      "Accuracy on test images: 0.947712\n",
      "\n",
      "\n",
      "Targeting inception_v3 with 2 classes\n",
      "------------------------------------------\n",
      "('Replacing the following state from initialized', 'inception_v3', ':', ['AuxLogits.fc.weight', 'AuxLogits.fc.bias', 'fc.weight', 'fc.bias'])\n",
      "('Resizing input images to max of', (299, 299))\n",
      "Transfering models to GPU(s)\n",
      "Retraining...\n",
      "[1,    30] loss: 1.641\n",
      "[1,    60] loss: 1.401\n",
      "[2,    30] loss: 1.389\n",
      "[2,    60] loss: 1.048\n",
      "[3,    30] loss: 1.448\n",
      "[3,    60] loss: 1.152\n",
      "[4,    30] loss: 1.333\n",
      "[4,    60] loss: 1.457\n",
      "[5,    30] loss: 1.008\n",
      "[5,    60] loss: 0.909\n",
      "[6,    30] loss: 1.242\n",
      "[6,    60] loss: 1.249\n",
      "[7,    30] loss: 0.902\n",
      "[7,    60] loss: 1.193\n",
      "[8,    30] loss: 0.914\n",
      "[8,    60] loss: 0.933\n",
      "[9,    30] loss: 1.055\n",
      "[9,    60] loss: 0.913\n",
      "[10,    30] loss: 0.833\n",
      "[10,    60] loss: 1.315\n",
      "[11,    30] loss: 0.871\n",
      "[11,    60] loss: 0.881\n",
      "[12,    30] loss: 0.876\n",
      "[12,    60] loss: 1.098\n",
      "[13,    30] loss: 0.934\n",
      "[13,    60] loss: 1.189\n",
      "[14,    30] loss: 0.990\n",
      "[14,    60] loss: 1.013\n",
      "[15,    30] loss: 1.031\n",
      "[15,    60] loss: 1.126\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 128/153\n",
      "Accuracy on test images: 0.836601\n",
      "\n",
      "\n",
      "Targeting resnet34 with 2 classes\n",
      "------------------------------------------\n",
      "('Replacing the following state from initialized', 'resnet34', ':', ['fc.weight', 'fc.bias'])\n",
      "('Resizing input images to max of', (224, 224))\n",
      "Transfering models to GPU(s)\n",
      "Retraining...\n",
      "[1,    30] loss: 1.097\n",
      "[1,    60] loss: 0.525\n",
      "[2,    30] loss: 0.460\n",
      "[2,    60] loss: 0.476\n",
      "[3,    30] loss: 0.662\n",
      "[3,    60] loss: 0.430\n",
      "[4,    30] loss: 0.586\n",
      "[4,    60] loss: 0.359\n",
      "[5,    30] loss: 0.723\n",
      "[5,    60] loss: 0.363\n",
      "[6,    30] loss: 0.430\n",
      "[6,    60] loss: 0.797\n",
      "[7,    30] loss: 0.301\n",
      "[7,    60] loss: 0.599\n",
      "[8,    30] loss: 0.456\n",
      "[8,    60] loss: 0.473\n",
      "[9,    30] loss: 0.674\n",
      "[9,    60] loss: 0.431\n",
      "[10,    30] loss: 0.714\n",
      "[10,    60] loss: 0.674\n",
      "[11,    30] loss: 0.387\n",
      "[11,    60] loss: 0.377\n",
      "[12,    30] loss: 0.304\n",
      "[12,    60] loss: 0.496\n",
      "[13,    30] loss: 0.661\n",
      "[13,    60] loss: 0.584\n",
      "[14,    30] loss: 0.432\n",
      "[14,    60] loss: 0.311\n",
      "[15,    30] loss: 0.430\n",
      "[15,    60] loss: 0.394\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 142/153\n",
      "Accuracy on test images: 0.928105\n",
      "\n",
      "\n",
      "Targeting squeezenet1_1 with 2 classes\n",
      "------------------------------------------\n",
      "('Replacing the following state from initialized', 'squeezenet1_1', ':', ['classifier.1.weight', 'classifier.1.bias'])\n",
      "('Resizing input images to max of', (224, 224))\n",
      "Transfering models to GPU(s)\n",
      "Retraining...\n",
      "[1,    30] loss: 0.573\n",
      "[1,    60] loss: 0.342\n",
      "[2,    30] loss: 0.357\n",
      "[2,    60] loss: 0.317\n",
      "[3,    30] loss: 0.203\n",
      "[3,    60] loss: 0.274\n",
      "[4,    30] loss: 0.171\n",
      "[4,    60] loss: 0.261\n",
      "[5,    30] loss: 0.215\n",
      "[5,    60] loss: 0.135\n",
      "[6,    30] loss: 0.086\n",
      "[6,    60] loss: 0.216\n",
      "[7,    30] loss: 0.195\n",
      "[7,    60] loss: 0.103\n",
      "[8,    30] loss: 0.098\n",
      "[8,    60] loss: 0.310\n",
      "[9,    30] loss: 0.139\n",
      "[9,    60] loss: 0.191\n",
      "[10,    30] loss: 0.128\n",
      "[10,    60] loss: 0.130\n",
      "[11,    30] loss: 0.146\n",
      "[11,    60] loss: 0.190\n",
      "[12,    30] loss: 0.178\n",
      "[12,    60] loss: 0.131\n",
      "[13,    30] loss: 0.101\n",
      "[13,    60] loss: 0.191\n",
      "[14,    30] loss: 0.148\n",
      "[14,    60] loss: 0.086\n",
      "[15,    30] loss: 0.155\n",
      "[15,    60] loss: 0.103\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 141/153\n",
      "Accuracy on test images: 0.921569\n",
      "\n",
      "\n",
      "Targeting vgg13 with 2 classes\n",
      "------------------------------------------\n",
      "('Replacing the following state from initialized', 'vgg13', ':', ['classifier.6.weight', 'classifier.6.bias'])\n",
      "('Resizing input images to max of', (224, 224))\n",
      "Transfering models to GPU(s)\n",
      "Retraining...\n",
      "[1,    30] loss: 0.366\n",
      "[1,    60] loss: 0.338\n",
      "[2,    30] loss: 0.118\n",
      "[2,    60] loss: 0.431\n",
      "[3,    30] loss: 0.197\n",
      "[3,    60] loss: 0.160\n",
      "[4,    30] loss: 0.154\n",
      "[4,    60] loss: 0.288\n",
      "[5,    30] loss: 0.123\n",
      "[5,    60] loss: 0.188\n",
      "[6,    30] loss: 0.108\n",
      "[6,    60] loss: 0.148\n",
      "[7,    30] loss: 0.186\n",
      "[7,    60] loss: 0.165\n",
      "[8,    30] loss: 0.180\n",
      "[8,    60] loss: 0.255\n",
      "[9,    30] loss: 0.148\n",
      "[9,    60] loss: 0.211\n",
      "[10,    30] loss: 0.324\n",
      "[10,    60] loss: 0.214\n",
      "[11,    30] loss: 0.170\n",
      "[11,    60] loss: 0.141\n",
      "[12,    30] loss: 0.287\n",
      "[12,    60] loss: 0.072\n",
      "[13,    30] loss: 0.059\n",
      "[13,    60] loss: 0.199\n",
      "[14,    30] loss: 0.176\n",
      "[14,    60] loss: 0.120\n",
      "[15,    30] loss: 0.134\n",
      "[15,    60] loss: 0.034\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 144/153\n",
      "Accuracy on test images: 0.941176\n",
      "\n",
      "---------------------\n",
      "TRAINING from scratch\n",
      "\n",
      "Targeting alexnet with 2 classes\n",
      "------------------------------------------\n",
      "('Resizing input images to max of', (224, 224))\n",
      "Transfering models to GPU(s)\n",
      "Training...\n",
      "[1,    30] loss: 0.695\n",
      "[1,    60] loss: 0.694\n",
      "[2,    30] loss: 0.693\n",
      "[2,    60] loss: 0.693\n",
      "[3,    30] loss: 0.693\n",
      "[3,    60] loss: 0.694\n",
      "[4,    30] loss: 0.693\n",
      "[4,    60] loss: 0.693\n",
      "[5,    30] loss: 0.693\n",
      "[5,    60] loss: 0.691\n",
      "[6,    30] loss: 0.694\n",
      "[6,    60] loss: 0.691\n",
      "[7,    30] loss: 0.689\n",
      "[7,    60] loss: 0.691\n",
      "[8,    30] loss: 0.687\n",
      "[8,    60] loss: 0.686\n",
      "[9,    30] loss: 0.687\n",
      "[9,    60] loss: 0.680\n",
      "[10,    30] loss: 0.681\n",
      "[10,    60] loss: 0.673\n",
      "[11,    30] loss: 0.660\n",
      "[11,    60] loss: 0.691\n",
      "[12,    30] loss: 0.667\n",
      "[12,    60] loss: 0.664\n",
      "[13,    30] loss: 0.653\n",
      "[13,    60] loss: 0.708\n",
      "[14,    30] loss: 0.650\n",
      "[14,    60] loss: 0.649\n",
      "[15,    30] loss: 0.645\n",
      "[15,    60] loss: 0.658\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 82/153\n",
      "Accuracy on test images: 0.535948\n",
      "\n",
      "\n",
      "Targeting densenet169 with 2 classes\n",
      "------------------------------------------\n",
      "('Resizing input images to max of', (224, 224))\n",
      "Transfering models to GPU(s)\n",
      "Training...\n",
      "[1,    30] loss: 0.730\n",
      "[1,    60] loss: 0.753\n",
      "[2,    30] loss: 0.603\n",
      "[2,    60] loss: 0.696\n",
      "[3,    30] loss: 0.741\n",
      "[3,    60] loss: 0.644\n",
      "[4,    30] loss: 0.634\n",
      "[4,    60] loss: 0.779\n",
      "[5,    30] loss: 0.689\n",
      "[5,    60] loss: 0.630\n",
      "[6,    30] loss: 0.643\n",
      "[6,    60] loss: 0.596\n",
      "[7,    30] loss: 0.633\n",
      "[7,    60] loss: 0.665\n",
      "[8,    30] loss: 0.636\n",
      "[8,    60] loss: 0.643\n",
      "[9,    30] loss: 0.730\n",
      "[9,    60] loss: 0.630\n",
      "[10,    30] loss: 0.650\n",
      "[10,    60] loss: 0.667\n",
      "[11,    30] loss: 0.703\n",
      "[11,    60] loss: 0.574\n",
      "[12,    30] loss: 0.625\n",
      "[12,    60] loss: 0.582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13,    30] loss: 0.661\n",
      "[13,    60] loss: 0.658\n",
      "[14,    30] loss: 0.658\n",
      "[14,    60] loss: 0.673\n",
      "[15,    30] loss: 0.645\n",
      "[15,    60] loss: 0.591\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 115/153\n",
      "Accuracy on test images: 0.751634\n",
      "\n",
      "\n",
      "Targeting inception_v3 with 2 classes\n",
      "------------------------------------------\n",
      "('Resizing input images to max of', (299, 299))\n",
      "Transfering models to GPU(s)\n",
      "Training...\n",
      "[1,    30] loss: 2.185\n",
      "[1,    60] loss: 2.170\n",
      "[2,    30] loss: 1.884\n",
      "[2,    60] loss: 2.380\n",
      "[3,    30] loss: 1.931\n",
      "[3,    60] loss: 2.445\n",
      "[4,    30] loss: 1.839\n",
      "[4,    60] loss: 2.162\n",
      "[5,    30] loss: 2.181\n",
      "[5,    60] loss: 2.234\n",
      "[6,    30] loss: 2.200\n",
      "[6,    60] loss: 1.952\n",
      "[7,    30] loss: 1.798\n",
      "[7,    60] loss: 2.165\n",
      "[8,    30] loss: 2.015\n",
      "[8,    60] loss: 2.311\n",
      "[9,    30] loss: 2.133\n",
      "[9,    60] loss: 1.889\n",
      "[10,    30] loss: 1.870\n",
      "[10,    60] loss: 2.018\n",
      "[11,    30] loss: 2.627\n",
      "[11,    60] loss: 2.062\n",
      "[12,    30] loss: 1.947\n",
      "[12,    60] loss: 2.125\n",
      "[13,    30] loss: 1.895\n",
      "[13,    60] loss: 1.716\n",
      "[14,    30] loss: 1.949\n",
      "[14,    60] loss: 1.798\n",
      "[15,    30] loss: 2.029\n",
      "[15,    60] loss: 1.963\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 76/153\n",
      "Accuracy on test images: 0.496732\n",
      "\n",
      "\n",
      "Targeting resnet34 with 2 classes\n",
      "------------------------------------------\n",
      "('Resizing input images to max of', (224, 224))\n",
      "Transfering models to GPU(s)\n",
      "Training...\n",
      "[1,    30] loss: 0.791\n",
      "[1,    60] loss: 0.738\n",
      "[2,    30] loss: 0.960\n",
      "[2,    60] loss: 0.853\n",
      "[3,    30] loss: 0.904\n",
      "[3,    60] loss: 1.041\n",
      "[4,    30] loss: 0.735\n",
      "[4,    60] loss: 1.088\n",
      "[5,    30] loss: 1.113\n",
      "[5,    60] loss: 0.795\n",
      "[6,    30] loss: 0.808\n",
      "[6,    60] loss: 0.652\n",
      "[7,    30] loss: 0.881\n",
      "[7,    60] loss: 0.708\n",
      "[8,    30] loss: 0.984\n",
      "[8,    60] loss: 0.714\n",
      "[9,    30] loss: 0.734\n",
      "[9,    60] loss: 0.939\n",
      "[10,    30] loss: 0.875\n",
      "[10,    60] loss: 0.686\n",
      "[11,    30] loss: 0.668\n",
      "[11,    60] loss: 0.754\n",
      "[12,    30] loss: 0.811\n",
      "[12,    60] loss: 0.736\n",
      "[13,    30] loss: 0.869\n",
      "[13,    60] loss: 0.669\n",
      "[14,    30] loss: 0.727\n",
      "[14,    60] loss: 0.890\n",
      "[15,    30] loss: 0.666\n",
      "[15,    60] loss: 0.895\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 93/153\n",
      "Accuracy on test images: 0.607843\n",
      "\n",
      "\n",
      "Targeting squeezenet1_1 with 2 classes\n",
      "------------------------------------------\n",
      "('Resizing input images to max of', (224, 224))\n",
      "Transfering models to GPU(s)\n",
      "Training...\n",
      "[1,    30] loss: 0.697\n",
      "[1,    60] loss: 0.693\n",
      "[2,    30] loss: 0.693\n",
      "[2,    60] loss: 0.693\n",
      "[3,    30] loss: 0.693\n",
      "[3,    60] loss: 0.693\n",
      "[4,    30] loss: 0.693\n",
      "[4,    60] loss: 0.693\n",
      "[5,    30] loss: 0.693\n",
      "[5,    60] loss: 0.693\n",
      "[6,    30] loss: 0.693\n",
      "[6,    60] loss: 0.693\n",
      "[7,    30] loss: 0.693\n",
      "[7,    60] loss: 0.693\n",
      "[8,    30] loss: 0.693\n",
      "[8,    60] loss: 0.693\n",
      "[9,    30] loss: 0.693\n",
      "[9,    60] loss: 0.693\n",
      "[10,    30] loss: 0.693\n",
      "[10,    60] loss: 0.693\n",
      "[11,    30] loss: 0.693\n",
      "[11,    60] loss: 0.693\n",
      "[12,    30] loss: 0.693\n",
      "[12,    60] loss: 0.693\n",
      "[13,    30] loss: 0.693\n",
      "[13,    60] loss: 0.693\n",
      "[14,    30] loss: 0.693\n",
      "[14,    60] loss: 0.693\n",
      "[15,    30] loss: 0.693\n",
      "[15,    60] loss: 0.693\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 70/153\n",
      "Accuracy on test images: 0.457516\n",
      "\n",
      "\n",
      "Targeting vgg13 with 2 classes\n",
      "------------------------------------------\n",
      "('Resizing input images to max of', (224, 224))\n",
      "Transfering models to GPU(s)\n",
      "Training...\n",
      "[1,    30] loss: 0.708\n",
      "[1,    60] loss: 0.707\n",
      "[2,    30] loss: 0.693\n",
      "[2,    60] loss: 0.686\n",
      "[3,    30] loss: 0.678\n",
      "[3,    60] loss: 0.674\n",
      "[4,    30] loss: 0.662\n",
      "[4,    60] loss: 0.709\n",
      "[5,    30] loss: 0.683\n",
      "[5,    60] loss: 0.677\n",
      "[6,    30] loss: 0.642\n",
      "[6,    60] loss: 0.652\n",
      "[7,    30] loss: 0.605\n",
      "[7,    60] loss: 0.649\n",
      "[8,    30] loss: 0.654\n",
      "[8,    60] loss: 0.647\n",
      "[9,    30] loss: 0.540\n",
      "[9,    60] loss: 0.690\n",
      "[10,    30] loss: 0.657\n",
      "[10,    60] loss: 0.669\n",
      "[11,    30] loss: 0.638\n",
      "[11,    60] loss: 0.645\n",
      "[12,    30] loss: 0.642\n",
      "[12,    60] loss: 0.632\n",
      "[13,    30] loss: 0.590\n",
      "[13,    60] loss: 0.590\n",
      "[14,    30] loss: 0.560\n",
      "[14,    60] loss: 0.560\n",
      "[15,    30] loss: 0.568\n",
      "[15,    60] loss: 0.614\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 99/153\n",
      "Accuracy on test images: 0.647059\n",
      "\n",
      "('Total time for training and evaluation', 501.11972069740295)\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "num_classes = 2\n",
    "print(\"RETRAINING\")\n",
    "\n",
    "for name in models_to_test:\n",
    "    print(\"\")\n",
    "    print(\"Targeting %s with %d classes\" % (name, num_classes))\n",
    "    print(\"------------------------------------------\")\n",
    "    model_pretrained, diff = load_model_merged(name, num_classes)\n",
    "    final_params = [d[0] for d in diff]\n",
    "    #final_params = None\n",
    "    \n",
    "    #Need to resize CIFAR to each net's standard input size \n",
    "    resize = [s[1] for s in input_sizes.items() if s[0] in name][0]\n",
    "    print(\"Resizing input images to max of\", resize)\n",
    "    trainloader, testloader = get_data(resize)\n",
    "    \n",
    "    if use_gpu:\n",
    "        print(\"Transfering models to GPU(s)\")\n",
    "        model_pretrained = torch.nn.DataParallel(model_pretrained).cuda()\n",
    "        \n",
    "    pretrained_stats = train_eval(model_pretrained, trainloader, testloader, final_params)\n",
    "    pretrained_stats['name'] = name\n",
    "    pretrained_stats['retrained'] = True\n",
    "    pretrained_stats['shallow_retrain'] = True\n",
    "    stats.append(pretrained_stats)\n",
    "    \n",
    "    print(\"\")\n",
    "\n",
    "print(\"---------------------\")\n",
    "print(\"TRAINING from scratch\")\n",
    "for name in models_to_test:\n",
    "    print(\"\")    \n",
    "    print(\"Targeting %s with %d classes\" % (name, num_classes))\n",
    "    print(\"------------------------------------------\")\n",
    "    model_blank = models.__dict__[name](num_classes=num_classes)\n",
    "\n",
    "    #Need to resize CIFAR to each net's standard input size \n",
    "    resize = [s[1] for s in input_sizes.items() if s[0] in name][0]\n",
    "    print(\"Resizing input images to max of\", resize)\n",
    "    trainloader, testloader = get_data(resize)\n",
    "    \n",
    "    if use_gpu:\n",
    "        print(\"Transfering models to GPU(s)\")\n",
    "        model_blank = torch.nn.DataParallel(model_blank).cuda()    \n",
    "        \n",
    "    blank_stats = train_eval(model_blank, trainloader, testloader)\n",
    "    blank_stats['name'] = name\n",
    "    blank_stats['retrained'] = False\n",
    "    blank_stats['shallow_retrain'] = False\n",
    "    stats.append(blank_stats)\n",
    "    \n",
    "    print(\"\")\n",
    "\n",
    "t = 0.0\n",
    "for s in stats:\n",
    "    t += s['eval_time'] + s['training_time']\n",
    "print(\"Total time for training and evaluation\", t)\n",
    "print(\"FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RETRAINING deep\n",
      "\n",
      "Targeting alexnet with 2 classes\n",
      "------------------------------------------\n",
      "('Replacing the following state from initialized', 'alexnet', ':', ['classifier.6.weight', 'classifier.6.bias'])\n",
      "('Resizing input images to max of', (224, 224))\n",
      "Transfering models to GPU(s)\n",
      "Training...\n",
      "[1,    30] loss: 0.798\n",
      "[1,    60] loss: 0.731\n",
      "[2,    30] loss: 0.634\n",
      "[2,    60] loss: 0.542\n",
      "[3,    30] loss: 0.546\n",
      "[3,    60] loss: 0.584\n",
      "[4,    30] loss: 0.551\n",
      "[4,    60] loss: 0.541\n",
      "[5,    30] loss: 0.392\n",
      "[5,    60] loss: 0.667\n",
      "[6,    30] loss: 0.603\n",
      "[6,    60] loss: 0.443\n",
      "[7,    30] loss: 0.363\n",
      "[7,    60] loss: 0.390\n",
      "[8,    30] loss: 0.500\n",
      "[8,    60] loss: 0.421\n",
      "[9,    30] loss: 0.421\n",
      "[9,    60] loss: 0.521\n",
      "[10,    30] loss: 0.516\n",
      "[10,    60] loss: 0.352\n",
      "[11,    30] loss: 0.455\n",
      "[11,    60] loss: 0.362\n",
      "[12,    30] loss: 0.459\n",
      "[12,    60] loss: 0.256\n",
      "[13,    30] loss: 0.474\n",
      "[13,    60] loss: 0.324\n",
      "[14,    30] loss: 0.324\n",
      "[14,    60] loss: 0.428\n",
      "[15,    30] loss: 0.216\n",
      "[15,    60] loss: 0.262\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 131/153\n",
      "Accuracy on test images: 0.856209\n",
      "\n",
      "\n",
      "Targeting densenet169 with 2 classes\n",
      "------------------------------------------\n",
      "('Replacing the following state from initialized', 'densenet169', ':', ['classifier.weight', 'classifier.bias'])\n",
      "('Resizing input images to max of', (224, 224))\n",
      "Transfering models to GPU(s)\n",
      "Training...\n",
      "[1,    30] loss: 0.624\n",
      "[1,    60] loss: 0.856\n",
      "[2,    30] loss: 0.320\n",
      "[2,    60] loss: 0.458\n",
      "[3,    30] loss: 0.459\n",
      "[3,    60] loss: 0.415\n",
      "[4,    30] loss: 0.259\n",
      "[4,    60] loss: 0.425\n",
      "[5,    30] loss: 0.571\n",
      "[5,    60] loss: 0.838\n",
      "[6,    30] loss: 0.492\n",
      "[6,    60] loss: 0.564\n",
      "[7,    30] loss: 0.675\n",
      "[7,    60] loss: 0.907\n",
      "[8,    30] loss: 0.581\n",
      "[8,    60] loss: 0.536\n",
      "[9,    30] loss: 0.721\n",
      "[9,    60] loss: 0.442\n",
      "[10,    30] loss: 0.405\n",
      "[10,    60] loss: 0.569\n",
      "[11,    30] loss: 0.638\n",
      "[11,    60] loss: 0.710\n",
      "[12,    30] loss: 0.695\n",
      "[12,    60] loss: 0.412\n",
      "[13,    30] loss: 0.610\n",
      "[13,    60] loss: 0.744\n",
      "[14,    30] loss: 0.467\n",
      "[14,    60] loss: 0.437\n",
      "[15,    30] loss: 0.640\n",
      "[15,    60] loss: 0.762\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 112/153\n",
      "Accuracy on test images: 0.732026\n",
      "\n",
      "\n",
      "Targeting inception_v3 with 2 classes\n",
      "------------------------------------------\n",
      "('Replacing the following state from initialized', 'inception_v3', ':', ['AuxLogits.fc.weight', 'AuxLogits.fc.bias', 'fc.weight', 'fc.bias'])\n",
      "('Resizing input images to max of', (299, 299))\n",
      "Transfering models to GPU(s)\n",
      "Training...\n",
      "[1,    30] loss: 1.641\n",
      "[1,    60] loss: 1.648\n",
      "[2,    30] loss: 2.023\n",
      "[2,    60] loss: 1.712\n",
      "[3,    30] loss: 1.815\n",
      "[3,    60] loss: 1.866\n",
      "[4,    30] loss: 1.779\n",
      "[4,    60] loss: 1.420\n",
      "[5,    30] loss: 1.227\n",
      "[5,    60] loss: 1.411\n",
      "[6,    30] loss: 1.394\n",
      "[6,    60] loss: 1.330\n",
      "[7,    30] loss: 1.349\n",
      "[7,    60] loss: 1.300\n",
      "[8,    30] loss: 1.217\n",
      "[8,    60] loss: 1.301\n",
      "[9,    30] loss: 0.971\n",
      "[9,    60] loss: 1.284\n",
      "[10,    30] loss: 1.353\n",
      "[10,    60] loss: 1.170\n",
      "[11,    30] loss: 1.280\n",
      "[11,    60] loss: 1.104\n",
      "[12,    30] loss: 1.197\n",
      "[12,    60] loss: 1.594\n",
      "[13,    30] loss: 1.147\n",
      "[13,    60] loss: 0.949\n",
      "[14,    30] loss: 1.124\n",
      "[14,    60] loss: 1.156\n",
      "[15,    30] loss: 1.385\n",
      "[15,    60] loss: 1.001\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 129/153\n",
      "Accuracy on test images: 0.843137\n",
      "\n",
      "\n",
      "Targeting resnet34 with 2 classes\n",
      "------------------------------------------\n",
      "('Replacing the following state from initialized', 'resnet34', ':', ['fc.weight', 'fc.bias'])\n",
      "('Resizing input images to max of', (224, 224))\n",
      "Transfering models to GPU(s)\n",
      "Training...\n",
      "[1,    30] loss: 0.570\n",
      "[1,    60] loss: 0.838\n",
      "[2,    30] loss: 0.775\n",
      "[2,    60] loss: 0.747\n",
      "[3,    30] loss: 0.465\n",
      "[3,    60] loss: 0.368\n",
      "[4,    30] loss: 0.455\n",
      "[4,    60] loss: 0.577\n",
      "[5,    30] loss: 0.775\n",
      "[5,    60] loss: 0.521\n",
      "[6,    30] loss: 0.527\n",
      "[6,    60] loss: 0.395\n",
      "[7,    30] loss: 0.393\n",
      "[7,    60] loss: 0.343\n",
      "[8,    30] loss: 0.547\n",
      "[8,    60] loss: 0.516\n",
      "[9,    30] loss: 0.411\n",
      "[9,    60] loss: 0.771\n",
      "[10,    30] loss: 0.433\n",
      "[10,    60] loss: 0.729\n",
      "[11,    30] loss: 0.588\n",
      "[11,    60] loss: 0.441\n",
      "[12,    30] loss: 0.331\n",
      "[12,    60] loss: 0.286\n",
      "[13,    30] loss: 0.180\n",
      "[13,    60] loss: 0.454\n",
      "[14,    30] loss: 0.373\n",
      "[14,    60] loss: 0.359\n",
      "[15,    30] loss: 0.504\n",
      "[15,    60] loss: 0.313\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 108/153\n",
      "Accuracy on test images: 0.705882\n",
      "\n",
      "\n",
      "Targeting squeezenet1_1 with 2 classes\n",
      "------------------------------------------\n",
      "('Replacing the following state from initialized', 'squeezenet1_1', ':', ['classifier.1.weight', 'classifier.1.bias'])\n",
      "('Resizing input images to max of', (224, 224))\n",
      "Transfering models to GPU(s)\n",
      "Training...\n",
      "[1,    30] loss: 0.669\n",
      "[1,    60] loss: 0.691\n",
      "[2,    30] loss: 0.689\n",
      "[2,    60] loss: 0.688\n",
      "[3,    30] loss: 0.687\n",
      "[3,    60] loss: 0.632\n",
      "[4,    30] loss: 0.701\n",
      "[4,    60] loss: 0.708\n",
      "[5,    30] loss: 0.691\n",
      "[5,    60] loss: 0.695\n",
      "[6,    30] loss: 0.691\n",
      "[6,    60] loss: 0.693\n",
      "[7,    30] loss: 0.693\n",
      "[7,    60] loss: 0.693\n",
      "[8,    30] loss: 0.693\n",
      "[8,    60] loss: 0.692\n",
      "[9,    30] loss: 0.693\n",
      "[9,    60] loss: 0.692\n",
      "[10,    30] loss: 0.693\n",
      "[10,    60] loss: 0.691\n",
      "[11,    30] loss: 0.688\n",
      "[11,    60] loss: 0.688\n",
      "[12,    30] loss: 0.683\n",
      "[12,    60] loss: 0.691\n",
      "[13,    30] loss: 0.702\n",
      "[13,    60] loss: 0.690\n",
      "[14,    30] loss: 0.668\n",
      "[14,    60] loss: 0.684\n",
      "[15,    30] loss: 0.614\n",
      "[15,    60] loss: 0.632\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 108/153\n",
      "Accuracy on test images: 0.705882\n",
      "\n",
      "\n",
      "Targeting vgg13 with 2 classes\n",
      "------------------------------------------\n",
      "('Replacing the following state from initialized', 'vgg13', ':', ['classifier.6.weight', 'classifier.6.bias'])\n",
      "('Resizing input images to max of', (224, 224))\n",
      "Transfering models to GPU(s)\n",
      "Training...\n",
      "[1,    30] loss: 0.411\n",
      "[1,    60] loss: 0.752\n",
      "[2,    30] loss: 0.605\n",
      "[2,    60] loss: 0.353\n",
      "[3,    30] loss: 0.556\n",
      "[3,    60] loss: 0.401\n",
      "[4,    30] loss: 0.296\n",
      "[4,    60] loss: 0.415\n",
      "[5,    30] loss: 0.320\n",
      "[5,    60] loss: 0.222\n",
      "[6,    30] loss: 0.264\n",
      "[6,    60] loss: 0.240\n",
      "[7,    30] loss: 0.595\n",
      "[7,    60] loss: 0.365\n",
      "[8,    30] loss: 0.220\n",
      "[8,    60] loss: 0.325\n",
      "[9,    30] loss: 0.098\n",
      "[9,    60] loss: 0.101\n",
      "[10,    30] loss: 0.203\n",
      "[10,    60] loss: 0.121\n",
      "[11,    30] loss: 0.099\n",
      "[11,    60] loss: 0.123\n",
      "[12,    30] loss: 0.074\n",
      "[12,    60] loss: 0.036\n",
      "[13,    30] loss: 0.068\n",
      "[13,    60] loss: 0.102\n",
      "[14,    30] loss: 0.140\n",
      "[14,    60] loss: 0.387\n",
      "[15,    30] loss: 0.146\n",
      "[15,    60] loss: 0.118\n",
      "Finished Training\n",
      "Evaluating...\n",
      "correct/total: 138/153\n",
      "Accuracy on test images: 0.901961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RETRAINING deep\")\n",
    "\n",
    "for name in models_to_test:\n",
    "    print(\"\")\n",
    "    print(\"Targeting %s with %d classes\" % (name, num_classes))\n",
    "    print(\"------------------------------------------\")\n",
    "    model_pretrained, diff = load_model_merged(name, num_classes)\n",
    "    \n",
    "    #Need to resize CIFAR to each net's standard input size \n",
    "    resize = [s[1] for s in input_sizes.items() if s[0] in name][0]\n",
    "    print(\"Resizing input images to max of\", resize)\n",
    "    trainloader, testloader = get_data(resize)\n",
    "    \n",
    "    if use_gpu:\n",
    "        print(\"Transfering models to GPU(s)\")\n",
    "        model_pretrained = torch.nn.DataParallel(model_pretrained).cuda()\n",
    "        \n",
    "    pretrained_stats = train_eval(model_pretrained, trainloader, testloader, None)\n",
    "    pretrained_stats['name'] = name\n",
    "    pretrained_stats['retrained'] = True\n",
    "    pretrained_stats['shallow_retrain'] = False\n",
    "    stats.append(pretrained_stats)\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export stats as .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('stats.csv', 'w') as csvfile:\n",
    "    fieldnames = stats[0].keys()\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for s in stats:\n",
    "        writer.writerow(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
